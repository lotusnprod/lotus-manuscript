## Methods {.page_break_before}

### Key Resources

<div style="font-size:9pt">

Table: Key resources {#tbl:key-resources}

| Reagent type (species) or resource | Designation | Source or reference | Identifiers | Additional information | 
|:---:|:---:|:------:|:---:|:------:| 
| Software, algorithm| Lotus-processor code| This work ([https://github.com/lotusnprod/lotus-processor](https://github.com/lotusnprod/lotus-processor))|| Archived at [https://doi.org/10.5281/zenodo.5802107](https://doi.org/10.5281/zenodo.5802107) | 
| Software, algorithm| Lotus-web code| This work ([https://github.com/lotusnprod/lotus-web](https://github.com/lotusnprod/lotus-web))|| Archived at [https://doi.org/10.5281/zenodo.5802119](https://doi.org/10.5281/zenodo.5802119) | 
| Software, algorithm| Lotus-wikidata-interact code| This work ([https://github.com/lotusnprod/lotus-wikidata-interact](https://github.com/lotusnprod/lotus-wikidata-interact)) || Archived at [https://doi.org/10.5281/zenodo.5802113](https://doi.org/10.5281/zenodo.5802113) | 
| Software, algorithm| Global Names Architeture| [https://globalnames.org](https://globalnames.org) | QID:[Q65691453](https://www.wikidata.org/wiki/Q65691453)|  See [Additional executable files](#additional-executable-files)  | 
| Software, algorithm| Java| [https://www.java.com](https://www.java.com) | QID:[Q251](https://www.wikidata.org/wiki/Q251)| | 
| Software, algorithm| Kotlin| [https://kotlinlang.org](https://kotlinlang.org) | QID:[Q3816639](https://www.wikidata.org/wiki/Q3816639)| See [Kotlin packages](#kotlin) | 
| Software, algorithm| Manubot| [https://manubot.org](https://manubot.org) | QID:[Q96473455](https://www.wikidata.org/wiki/Q96473455) RRID:SCR_018553 | Repository available at [https://github.com/lotusnprod/lotus-manuscript](https://github.com/lotusnprod/lotus-manuscript) | 
| Software, algorithm| NPClassifier| [https://npclassifier.ucsd.edu](https://npclassifier.ucsd.edu) ||| 
| Software, algorithm| OPSIN| [https://github.com/dan2097/opsin](https://github.com/dan2097/opsin) | QID:[Q26481302](https://www.wikidata.org/wiki/Q26481302)|| 
| Software, algorithm| Python Programming Language| [https://www.python.org](https://www.python.org) | QID:[Q28865](https://www.wikidata.org/wiki/Q28865) RRID:SCR_008394| See [Python packages](#python) | 
| Software, algorithm| R Project for Statistical Computing| [https://www.r-project.org](https://www.r-project.org) | QID:[Q206904](https://www.wikidata.org/wiki/Q206904) RRID:SCR_001905| See [R packages](#r) | 
| Software, algorithm| Molconvert| [https://docs.chemaxon.com/display/docs/molconvert.md](https://docs.chemaxon.com/display/docs/molconvert.md) | QID:[Q55377678](https://www.wikidata.org/wiki/Q55377678)|| 
| Software, algorithm| Wikidata | [https://www.wikidata.org](https://www.wikidata.org) | QID:[Q2013](https://www.wikidata.org/wiki/Q2013) RRID:SCR_018492| Project page [https://www.wikidata.org/wiki/Wikidata:WikiProject_Chemistry/Natural_products](https://www.wikidata.org/wiki/Wikidata:WikiProject_Chemistry/Natural_products)|
| Other| Lotus custom dictionaries| This work || Archived at [https://doi.org/10.5281/zenodo.5801798](https://doi.org/10.5281/zenodo.5801798) | 
| Other| Chemical identifier resolver| [https://cactus.nci.nih.gov/chemical/structure](https://cactus.nci.nih.gov/chemical/structure) ||| 
| Other| CrossRef | [https://www.crossref.org](https://www.crossref.org) | QID:[Q5188229](https://www.wikidata.org/wiki/Q5188229) RRID:SCR_003217||
| Other| PubChem| [https://pubchem.ncbi.nlm.nih.gov](https://pubchem.ncbi.nlm.nih.gov) | QID:[Q278487](https://www.wikidata.org/wiki/Q278487) RRID:SCR_004284| LOTUS data [https://pubchem.ncbi.nlm.nih.gov/source/25132](https://pubchem.ncbi.nlm.nih.gov/source/25132) | 
| Other| PubMed| [https://pubmed.ncbi.nlm.nih.gov](https://pubmed.ncbi.nlm.nih.gov) | QID:[Q180686](https://www.wikidata.org/wiki/Q180686) RRID:SCR_004846||
| Other| Taxonomic data sources | [https://resolver.globalnames.org/data_sources](https://resolver.globalnames.org/data_sources) || See [Translation](#translation) | 
| Other| Natural Products data sources ||| See [Appendix 1](#appendix-1-data-sources-list) | 

</div>

### Data Gathering {.page_break_before}

Before their inclusion, the overall quality of the source was manually assessed to estimate, both, the quality of referenced structure-organism pairs and the lack of ambiguities in the links between data and references.
This led to the identification of thirty-six electronic NP resources as valuable LOTUS input.
Data from the proprietary Dictionary of Natural Products (DNP v 29.2) was also used for comparison purposes only and is not publicly disseminated.
[FooDB](https://foodb.ca) was also curated but not publicly disseminated since its license proscribed sharing in Wikidata.
[Appendix 1](#appendix-1-data-sources-list) gives all necessary details regarding electronic NP resources access and characteristics.

Manual inspection of each electronic NP resource revealed that the structure, organism, and reference fields were widely variable in format and contents, thus requiring standardization to be comparable.
The initial stage consisted of writing tailored scripts that are capable of harmonizing and categorizing knowledge from each source (Figure @fig:workflow).
This transformative process led to three categories: fields relevant to the chemical structure described, to the producing biological organism, and the reference describing the occurrence of the chemical structure in the producing biological organism.
This process resulted in categorized columns for each source, providing an initial harmonized format for each table.

For all thirty-eight sources, if a single file or multiple files were accessible *via* a download option including FTP, data was gathered that way.
For some sources, data was scraped (cf. [Appendix 1](#appendix-1-data-sources-list)).
All scraping scripts can be found in the [lotus-processor](https://github.com/lotusnprod/lotus-processor) repository in the [src/1_gathering](https://github.com/lotusnprod/lotus-processor/tree/main/src/1_gathering) directory (under each respective subdirectory).
Data extraction scripts for the DNP are available and should allow users with a DNP license only to further exploit the data ([src/1_gathering/db/dnp](https://github.com/lotusnprod/lotus-processor/tree/main/src/1_gathering/db/dnp)).
The chemical structure fields, organism fields, and reference fields were manually categorized into three, two, and ten subcategories, respectively.
For chemical structures, "InChI", "SMILES", and "chemical name" (not necessarily IUPAC).
For organisms, "clean" and "dirty", meaning lot text not referred to the canonical name was present or the organism was not described by its canonical name (e.g. "Compound isolated from the fresh leaves of *Citrus* spp.").
For the references, the original reference was kept in the "original" field.
When the format allowed it, references were divided into: "authors", "doi", "external", "isbn", "journal", "original", "publishing details", "pubmed", "title", "split".
The generic "external" field was used for all external cross-references to other websites or electronic NP resources (e.g. "also in knapsack").
The last subcategory, "split", corresponds to a still non-atomic field after the removal of parts of the original reference.
Other field titles are self-explanatory.
The producing organism field was kept as a single field.

### Data Harmonization

To perform the harmonization of all previously gathered sources, sixteen columns were chosen as described above.
Upon electronic NP resources harmonization, resulting subcategories were divided and subject to further processing.
The "chemical structure" fields were divided into files according to their subcategories ("InChI", "names" and "SMILES").
A file containing all initial structures from all three subcategories was also generated.
The same procedure was followed for organisms and references.

### Data Processing

To obtain an unambiguously referenced structure-organism pair for Wikidata dissemination, the initial sixteen columns were translated and processed into three fields: the reported structure, the organism canonical name, and the reference.
The structure was reported as InChI, together with its SMILES and InChIKey translation.
The biological organism field was reported as three minimal necessary and sufficient fields, namely its canonical name and the taxonID and taxonomic DB corresponding to the latter.
The reference was reported as four minimal fields, namely reference title, DOI, PMCID, and PMID, one being sufficient.
For the forthcoming translation processes, automated solutions were used when available.
However, for specific cases (common or vernacular names of the biological organisms, Traditional Chinese Medicine (TCM) names, and conversion between digital reference identifiers), no solution existed, thus requiring the use of tailored dictionaries.
Their construction is detailed in the [Dictionaries](#dictionaries) section.
The initial entries (containing one or multiple producing organisms per structure, with one or multiple accepted names per organism) were processed into 2M+ referenced structure-organism pairs.

#### Chemical Structures

To retrieve as much information as possible from the original structure field(s) of each of the sources, the following procedure was followed.
Allowed structural fields for the sources were divided into two types: structural (InChI, SMILES) or nominal (chemical name, not necessarily IUPAC).
If multiple fields were present, structural identifiers were preferred over structure names.
Among structural identifiers, when both identifiers were present, SMILES was preferred over InChI.
InChI were translated to SMILES using the RDKit (2021.09.2) implementation in Python 3.8 ([src/2_curating/2_editing/structure/1_translating/inchi.py](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/2_editing/structure/1_translating/inchi.py)).
They were first converted to [ROMol](https://www.rdkit.org/docs/cppapi/ROMol_8h.html#details) objects which were then converted to SMILES.
When no structural identifier was available, the nominal identifier was translated to InChI first thanks to [OPSIN](https://github.com/dan2097/opsin) [@doi:10/b2zkr9], a fast Java-based translation open-source solution.
If no translation was obtained, chemical names were then submitted to the PUG-REST, the interface for programmatic access to PubChem [@doi:10.1093/nar/gky294; @doi:10.1093/nar/gkv396].
If again no translation was obtained, candidates were then submitted to the [Chemical Identifier Resolver](https://cactus.nci.nih.gov).
Before the translation process, some typical chemical structure-related greek characters (such as *α*, *ß*) were replaced by their textual equivalents (alpha, beta) to obtain better results.
All pre-translation steps are included in the preparing_name function and are available in [src/r/preparing_name.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/r/preparing_name.R).

The chemical sanitization step sought to standardize the representation of chemical structures coming from different sources.
It consisted of three main stages (standardizing, fragment removal, and uncharging) achieved *via* the MolVS package.
The initial standardizer function consists of six stages (RDKit Sanitization, RDKit Hs removal, Metals Disconnection, Normalization, Acids Reionization, and Stereochemistry recalculation) detailed in the [molvs documentation](https://molvs.readthedocs.io/en/latest/guide/standardize.html).
In a second step, the FragmentRemover functionality was applied using a list of SMARTS to detect and remove common counterions and crystallization reagents sometimes occurring in the input DB.
Finally, the Uncharger function was employed to neutralize molecules when appropriate.

[Molconvert](https://docs.chemaxon.com/display/docs/molconvert.md) function of the MarvinSuite was used for traditional and IUPAC names translation, Marvin 20.19, [ChemAxon](https://www.chemaxon.com).
When stereochemistry was not fully defined, (+) and (-) symbols were removed from names.
All details are available in the following script: [src/2_curating/2_editing/structure/4_enriching/naming.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/2_editing/structure/4_enriching/naming.R).
Chemical classification of all resulting structures was done using classyfireR [@doi:10/gc5tqv] and [NPClassifier API](https://ccms-ucsd.github.io/GNPSDocumentation/api/#structure-np-classifier).

After manual evaluation, structures remaining as dimers were discarded (all structures containing a "." in their SMILES were removed).

From the 283,267 initial InChI, 242,068 (85%) sanitized structures were obtained, of which 185,929 (77%) had complete stereochemistry defined.
203,718 (72%) were uploaded to Wikidata.
From the 248,185 initial SMILES, 207,658 (84%) sanitized structures were obtained, of which 98,685 (48%) had complete stereochemistry defined.
174,091 (70%) were uploaded to Wikidata.
From the 49,675 initial chemical names, 27,932 (56%) sanitized structures were obtained, of which 17,460 (63%) had complete stereochemistry defined.
23,036 (46%) were uploaded to Wikidata.
In total, 163,800 structures with fully defined stereochemistry were uploaded as "chemical compounds" ([Q11173](https://www.wikidata.org/wiki/Q11173)), and 106,669 structures without fully defined stereochemistry were uploaded as "group of stereoisomers" ([Q59199015](https://www.wikidata.org/wiki/Q59199015)).


#### Biological Organisms {.page_break_before}

The processing at the biological organism’s level had three objectives: convert the original organism string to (a) taxon name(s), atomize fields containing multiple taxon names, and deduplicate synonyms.
The original organism strings were treated with [Global Names Finder](https://github.com/gnames/gnfinder) (GNF) and [Global Names Verifier](https://github.com/gnames/gnverifier) (GNV), both tools coming from the [Global Names Architecture](http://globalnames.org) (GNA) a system of web services that helps people to register, find, index, check and organize biological scientific names and interconnect on-line information about species.
GNF allows scientific name recognition within raw text blocks and searches for found scientific names among public taxonomic DB.
GNV takes names or lists of names and verifies them against various biodiversity data sources.
Canonical names, their taxonID, and the taxonomic DB they were found in were retrieved.
When a single entry led to multiple canonical names (accepted synonyms), all of them were kept.
Because both GNF and GNV recognize scientific names and not common ones, common names were translated before a second resubmission.

##### Dictionaries

To perform the translations from common biological organism name to latin scientific name, specialized dictionaries included in DrDuke, FooDB, PhenolExplorer were aggregated together with the translation dictionary of [GBIF Backbone Taxonomy](https://www.gbif.org/dataset/d7dddbf4-2cf0-4f39-9b2a-bb099caae36c).
The script used for this was [src/1_gathering/translation/common.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/1_gathering/translation/common.R).
When the canonical translation of a common name contained a specific epithet that was not initially present, the translation pair was discarded (for example, "Aloe" translated in "*Aloe vera*" was discarded).
Common names corresponding to a generic name were also discarded (for example "Kiwi" corresponding to the synonym of an *Apteryx* spp. ([https://www.gbif.org/species/4849989](https://www.gbif.org/species/4849989))).
When multiple translations were given for a single common name, the following procedure was followed: the canonical name was split into species name, genus name, and possible subnames.
For each common name, genus names and species names were counted.
If both the species and genus names were consistent at more than 50%, they were considered consistent overall and, therefore, kept (for example, "Aberrant Bush Warbler" had "*Horornis flavolivaceus*" and "*Horornis flavolivaceus intricatus*" as translation; as both the generic ("*Horornis*") and the specific ("*flavolivaceus*") epithets were consistent at 100%, both ("*Horornis flavolivaceus*") were kept).
When only the generic epithet had more than 50% consistency, it was kept (for example, "Angelshark" had "*Squatina australis*" and "*Squatina squatina*" as translation, so only "*Squatina*" was kept).
Some unspecific common names were removed (see [https://doi.org/10.5281/zenodo.5801816](https://doi.org/10.5281/zenodo.5801816) [@doi:10.5281/zenodo.5801816]) and only common names with more than three characters were kept.
This resulted in 181,891 translation pairs further used for the conversion from common names to scientific names.
For TCM names, translation dictionaries from TCMID, TMMC, and coming from the Chinese Medicine Board of Australia were aggregated.
The script used for this was [src/1_gathering/translation/tcm.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/1_gathering/translation/tcm.R).
Some unspecific common names were removed (see [https://doi.org/10.5281/zenodo.5801816](https://doi.org/10.5281/zenodo.5801816) [@doi:10.5281/zenodo.5801816]).
Careful attention was given to the Latin genitive translations and custom dictionaries were written (see [https://doi.org/10.5281/zenodo.5801816](https://doi.org/10.5281/zenodo.5801816) [@doi:10.5281/zenodo.5801816]).
Organ names of the producing organism were removed to avoid wrong translation (see [https://doi.org/10.5281/zenodo.5801816](https://doi.org/10.5281/zenodo.5801816) [@doi:10.5281/zenodo.5801816]).
This resulted in 7,070 translation pairs.
Both common and TCM translation pairs were then ordered by decreasing string length, first translating the longer names to avoid part of them being translated incorrectly.

##### Translation

To ensure compatibility between obtained taxonID with Wikidata, the taxonomic DB 3 ([ITIS](https://www.itis.gov)), 4 ([NCBI](https://www.ncbi.nlm.nih.gov/taxonomy)), 5 ([Index Fungorum](http://www.indexfungorum.org)), 6 ([GRIN Taxonomy for Plants](http://wgb.cimmyt.org/gringlobal/taxon/abouttaxonomy.aspx?language=en&chapter=scope)), 8 ([The Interim Register of Marine and Nonmarine Genera](https://www.irmng.org)), 9 ([World Register of Marine Species](http://www.marinespecies.org)), 11 ([GBIF Backbone Taxonomy](https://www.gbif.org)), 12 ([Encyclopedia of Life](https://eol.org)), 118 ([AmphibiaWeb](https://amphibiaweb.org)), 128 ([ARKive](https://www.wildscreen.org/arkive-closure)), 132 ([ZooBank](http://zoobank.org)), 147 ([Database of Vascular Plants of Canada (VASCAN)](http://data.canadensys.net/vascan/search)), 148 ([Phasmida Species File](http://phasmida.speciesfile.org)), 150 ([USDA NRCS PLANTS Database](https://plants.sc.egov.usda.gov)), 155 ([FishBase](https://www.fishbase.se)), 158 ([EUNIS](https://eunis.eea.europa.eu)), 163 ([IUCN Red List of Threatened Species](https://www.iucnredlist.org)), 164 ([BioLib.cz](https://www.biolib.cz)), 165 ([Tropicos - Missouri Botanical Garden](https://www.tropicos.org)), 167 ([The International Plant Names Index](https://www.ipni.org)), 169 ([uBio NameBank](http://ubio.org)), 174 ([The Mammal Species of The World](https://www.departments.bucknell.edu/biology/resources/msw3)), 175 ([BirdLife International](http://www.birdlife.org)), 179 ([Open Tree of Life](https://tree.opentreeoflife.org)), 180 ([iNaturalist](https://www.inaturalist.org)) and 187 ([The eBird/Clements Checklist of Birds of the World](https://ebird.org/science/use-ebird-data/the-ebird-taxonomy)) were chosen.
All other available taxonomic DB are listed at [http://index.globalnames.org/datasource](http://index.globalnames.org/datasource).
To retrieve as much information as possible from the original organism field of each of the sources, the following procedure was followed: First, a scientific name recognition step, allowing us to retrieve canonical names was carried ([src/2_curating/2_editing/organisms/subscripts/1_processingOriginal.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/2_editing/organisms/subscripts/1_processingOriginal.R)).
Then, a subtraction step of the obtained canonical names from the original field was applied, to avoid unwanted translation of parts of canonical names.
For example, _Bromus mango_ contains "mango" as a specific epithet, which is also the common name for _Mangifera indica_.
After this subtraction step, the remaining names were translated from vernacular (common) and TCM names to scientific names, with help of the dictionaries.
For performance reasons, this processing step was written in Kotlin and used coroutines to allow efficient parallelization of that process ([src/2_curating/2_editing/organisms/2_translating_organism_kotlin/](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/2_editing/organisms/2_translating_organism_kotlin/)).
They were subsequently submitted again to scientific name recognition ([src/2_curating/2_editing/organisms/3_processingTranslated.R](http://src/2_curating/2_editing/organisms/3_processingTranslated.R)).

After full resolution of canonical names, all obtained names were submitted to rotl [@doi:10.1111/2041-210x.12593] to obtain a unified taxonomy.
From the 88,395 initial "clean" organism fields, 43,936 (50%) canonical names were obtained, of which 32,285 (37%) were uploaded to Wikidata.
From the 300 initial "dirty" organism fields, 250 (83%) canonical names were obtained, of which 208 (69%) were uploaded to Wikidata.

#### References 

The [Rcrossref](https://cran.r-project.org/web/packages/rcrossref) package [@chamberlainRcrossrefClientVarious2020] interfacing with the [Crossref](https://www.crossref.org) API was used to translate references from their original subcategory ("original", "publishingDetails", "split", "title") to a DOI, the title of its corresponding article, the journal it was published in, its date of publication and the name of the first author.
The first twenty candidates were kept and ranked according to the score returned by Crossref, which is a [tf-idf](https://lucene.apache.org/core/8_8_0/core/org/apache/lucene/search/similarities/TFIDFSimilarity.html) score.
For DOI and PMID, only a single candidate was kept.
All DOIs were also translated with this method, to eventually discard any DOI not leading to an object.
PMIDs were translated, thanks to the entrez_summary function of the [rentrez](https://cran.r-project.org/web/packages/rentrez) package [@doi:10/gh5ptg].
Scripts used for all subcategories of references are available in the directory [src/2_curating/2_editing/reference/1_translating/](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/2_editing/reference/1_translating/).
Once all translations were made, results coming from each subcategory were integrated, ([src/2_curating/2_editing/reference/2_integrating.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/2_editing/reference/2_integrating.R)) and the producing organism related to the reference was added for further treatment.
Because the crossref score was not informative enough, at least one other metric was chosen to complement it.
The first metric was related to the presence of the producing organism’s generic name in the title of the returned article.
If the title contained the generic name of the organism, a score of 1 was given, else 0.
Regarding the subcategories "doi", "pubmed" and "title", for which the same subcategory was retrieved *via* crossref or rentrez, distances between the input’s string and the candidates’ one were calculated.
Optimal string alignment (restricted [Damerau-Levenshtein distance](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)) was used as a method.
Among "publishing details", "original" and "split" categories, three additional metrics were used: If the journal name was present in the original field, a score of 1 was given, else 0.
If the name of the first author was present in the original field, a score of 1 was given, else 0.
Those three scores were then summed together.
All candidates were first ordered according to their crossref score, then by the complement score for related subcategories, then again according to their title-producing organism score, and finally according to their translation distance score.
After this re-ranking step, only the first candidate was kept.
Finally, the Pubmed PMCID dictionary ([PMC-ids.csv.gz](https://ftp.ncbi.nlm.nih.gov/pub/pmc/PMC-ids.csv.gz)) was used to perform the translations between DOI, PMID, and PMCID ([src/2_curating/2_editing/reference/3_processing.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/2_editing/reference/3_processing.R)).

From the 36,710 initial "original" references, 21,970 (60%) references with sufficient quality were obtained, of which 15,588 (71%) had the organism name in their title.
14,710 (40%) were uploaded to Wikidata.
From the 21,953 initial "pubmed" references, 9,452 (43%) references with sufficient quality were obtained, of which 6,098 (65%) had the organism name in their title.
5,553 (25%) were uploaded to Wikidata.
From the 37,371 initial "doi" references, 20,139 (54%) references with sufficient quality were obtained, of which 15,727 (78%) had the organism name in their title.
15,351 (41%) were uploaded to Wikidata.
From the 29,600 initial "title" references, 17,417 (59%) references with sufficient quality were obtained, of which 12,675 (73%) had the organism name in their title.
10,725 (36%) were uploaded to Wikidata.
From the 11,325 initial "split" references, 5,856 (52%) references with sufficient quality were obtained, of which 3,206 (55%) had the organism name in their title.
2,854 (25%) were uploaded to Wikidata.
From the 3,314 initial "publishingDetails" references, 119 (4%) references with sufficient quality were obtained, of which 59 (50%) had the organism name in their title.
58 (2%) were uploaded to Wikidata.

### Data Realignment

In order to fetch back the referenced structure-organism pairs links in the original data, the processed structures, processed organisms, and processed references were re-aligned with the initial entries.
This resulted in 6.2M+ referenced structure-organism pairs.
Those pairs were not unique, with redundancies among electronic NP resources and different original categories leading to the same final pair (for example, entry reporting InChI=1/C21H20O12/c22-6-13-15(27)17(29)18(30)21(32-13)33-20-16(28)14-11(26)4-8(23)5-12(14)31-19(20)7-1-2-9(24)10(25)3-7/h1-5,13,15,17-18,21-27,29-30H,6H2/t13-,15+,17+,18-,21+/m1/s1 in *Crataegus oxyacantha* or InChI=1S/C21H20O12/c22-6-13-15(27)17(29)18(30)21(32-13)33-20-16(28)14-11(26)4-8(23)5-12(14)31-19(20)7-1-2-9(24)10(25)3-7/h1-5,13,15,17-18,21-27,29-30H,6H2/t13-,15+,17+,18-,21+/m1/s1 in *Crataegus stevenii* both led to OVSQVDMCBVZWGM-DTGCRPNFSA-N in *Crataegus monogyna*).
After deduplication, 2M+ unique structure-organism pairs were obtained.

After the curation of all three objects, all of them were put together again.
Therefore, the original aligned table containing the original pairs was joined with each curation result.
Only entries containing a structure, an organism, and a reference after curation were kept.
Each curated object was divided into minimal data (for Wikidata upload) and metadata.
A dictionary containing original and curated object translations was written for each object to avoid those translations being made again during the next curation step ([src/2_curating/3_integrating.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/2_curating/3_integrating.R)).

### Data Validation 

The pairs obtained after curation were of different quality.
Globally, structure and organism translation was satisfactory whereas reference translation was not.
Therefore, to assess the validity of the obtained results, a randomized set of 420 referenced structure-organism pairs was sampled in each reference subcategory and validated or rejected manually.
Entries were sampled with at least 55 of each reference subcategory present (to get a representative idea of each subcategory) ([src/3_analyzing/1_sampling.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/3_analyzing/1_sampling.R)).
An entry was only validated if: *i)* the structure (as any structural descriptor that could be linked to the final sanitized InChIKey) was described in the reference *ii)* the producing organism (as any organism descriptor that could be linked to the accepted canonical name) was described in the reference and *iii)* the reference was describing the occurrence of the chemical structure in the biological organism.
Results obtained on the manually analyzed set were categorized according to the initial reference subcategory and are detailed in [Appendix 2](#appendix-2-summary-of-the-validation-statistics).
To improve these results, further processing of the references was needed.
This was done by accepting entries whose reference was coming from a DOI, a PMID, or from a title which restricted Damerau-Levenshtein distance between original and translated was lower than ten or if it was coming from one of the three main journals where NP occurrences are commonly expected to be published (i.e., *Journal of Natural Products*, *Phytochemistry*, or *Journal of Agricultural and Food Chemistry*).
For "split", "publishingDetails" and "original" subcategories, the year of publication of the obtained reference, its journal, and the name of the first author were searched in the original entry and if at least two of them were present, the entry was kept.
Entries were then further filtered to keep the ones where the reference title contained the first element of the detected canonical name.
Except for COCONUT, exceptions to this filter were made for all DOI-based references. 
The function resulting from those rules is ([filter_dirty.R](https://github.com/lotusnprod/lotus-processor/blob/main/src/r/filter_dirty.R)).
To validate those filtering criteria, an additional set of 100 structure-organism pairs were manually analyzed.
F0.5 score was used as a metric.
F0.5 score is a modified F1 score where precision has twice more weight than recall.
The F-score was calculated with ß = 0.5, as in Equation @eq:validation: 

${F_{\beta}\ =\ \left(1+\beta^2\right)\cdot\frac{precision\cdot recall}{\left(\beta^2\ \cdot\ precision\right)\ +\ recall}}$ {#eq:validation}

Based on this first manually validated dataset, filtering criteria ([src/r/filter_dirty.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/r/filter_dirty.R)) were established to maximize precision and recall.
Another 100 entries were sampled, this time respecting the whole set ratios.
After manual validation, 97% of true positives were reached on the second set.
A summary of the validation results is given in [Appendix 2](#appendix-2-summary-of-the-validation-statistics).
Once validated, the filtering criteria were established to the whole curated set to filter entries chosen for dissemination ([src/3_analyzing/2_validating.R](https://github.com/lotusnprod/lotus-processor/tree/main/src/3_analyzing/2_validating.R)).

### Unit Testing

To provide robustness of the whole process and code, unit tests and partial data full-tests were written.
They can run on the developer machine but also on the CI/CD system (GitHub) upon each commit to the codebase.

Those tests assess that the functions are providing results coherent with what is expected especially for edge cases detected during the development.
The Kotlin code has tests based on JUnit and code quality control checks based on Ktlint, Detekt and Ben Mane's version plugin.

### Data Dissemination

#### Wikidata

All the data produced for this work has been made available on Wikidata under a [Creative Commons 0](https://creativecommons.org/publicdomain/zero/1.0) license according to [Wikidata:Licensing](https://www.wikidata.org/wiki/Wikidata:Licensing).
This is a "No-rights-reserved" license that places no restrictions on reuse.

#### Lotus.NaturalProducts.Net (LNPN)

The web interface is implemented following the same protocol as described in the COCONUT publication [@doi:10/ghssx5] i.e. the data are stored in a MongoDB repository, the backend runs with Kotlin and Java, using the Spring framework, and the frontend is written in React.js, and completely Dockerized.
In addition to the diverse search functions available through this web interface, an API is also implemented, allowing programmatic LNPN querying.
The complete API usage is described on the "Documentation" page of the website.
LNPN is part of the NaturalProducts.net portal, an initiative aimed at gathering diverse open NP resources in one place.

### Data Interaction

#### Data Retrieval

Bulk retrieval of a frozen (2021-12-20) version of LOTUS data is also available at [https://doi.org/10.5281/zenodo.5794106](https://doi.org/10.5281/zenodo.5794106) [@doi:10.5281/zenodo.5794106].


The [download lotus](https://github.com/lotusnprod/lotus-wikidata-interact/blob/main/downloadLotus/README.md) part of [lotus-wikidata-interact](https://github.com/lotusnprod/lotus-wikidata-interact) allows the download of all chemical compounds with a "found in taxon" property.
That way, it does not only get the data produced by this work, but any that would have existed beforehand or that would have been added directly on Wikidata by our users.
It makes a copy of all the entities (compounds, taxa, references) into a local triplestore that can be queried with SPARQL as is or converted to a TSV file for inclusion in other projects.
It is currently adapted to export directly into the SSOT thus allowing direct reuse by the processing/curation pipeline.

#### Data Addition 

##### Wikidata

Data is loaded by the Kotlin importer available in the [upload lotus](https://github.com/lotusnprod/lotus-wikidata-interact/blob/main/uploadLotus/README.md) part of [lotus-wikidata-interact](https://github.com/lotusnprod/lotus-wikidata-interact) repository under a GPL V3 license and imported into Wikidata.
The importer processes the curated outputs grouping references, organisms, and compounds together.
It then checks if they already exist in Wikidata (using SPARQL or a direct connection to Wikidata depending on the kind of data).
It then uses *update* or *insert*, also called *upsert*, the entities as needed.
The script currently takes the tabular file of the referenced structure-organism pairs resulting from the LOTUS curation process as input.
Before upload, a filtering step is performed in order to avoid re-uploading entries we already uploaded.
This way, if modifications occur in Wikidata, it will not be erased by the next iteration of the importer.
The importer is currently being adapted to use directly the SSOT and avoid an unnecessary conversion step.
To import references, it first double checks for the presence of duplicated DOIs and utilizes the [Crossref REST API](https://www.crossref.org/education/retrieve-metadata/rest-api) to retrieve metadata associated with the DOI, the support for other citation sources such as Europe PMC is in progress.
The structure-related fields are only subject to limited processing: basic formatting of the molecular formula by subscripting of the numbers.
Due to limitations in Wikidata, the molecule names are dropped if they are longer than 250 characters and likewise the InChI strings cannot be stored if they are longer than 1500 characters.

Uploaded taxonomical DB identifiers are currently restricted to ITIS, GBIF, NCBI Taxon, Index Fungorum, IRMNG, WORMS, VASCAN, and iNaturalist, and newly OTL.
The taxa levels are currently limited to family, subfamily, tribe, subtribe, genus, species, variety.
The importer checks for the existence of each item based on their InChIKey and upserts the compound with the *found in taxon* statement and the associated organisms and references.

##### LNPN

From the onset, LNPN has been importing data directly from the frozen tabular data of the LOTUS dataset ([https://doi.org/10.5281/zenodo.5794106](https://doi.org/10.5281/zenodo.5794106) [@doi:10.5281/zenodo.5794106]).
In future versions, LNPN will directly feed on the SSOT.

##### Data Edition

The bot framework [lotus-wikidata-interact](https://github.com/lotusnprod/lotus-wikidata-interact) was adapted such that, in addition to batch upload capabilities, it can also edit erroneously created entries on Wikidata.
As massive edits have a large potential to disrupt otherwise good data, progressive deployment of this script is used, starting by editing progressively 1, 10, then 100 entries that are manually checked.
Upon validation of 100 entries, the full script is run and check its behavior checked at regular intervals.
An example of a corrected entry is as follows: [https://www.wikidata.org/w/index.php?title=Q105349871&type=revision&diff=1365519277&oldid=1356145998](https://www.wikidata.org/w/index.php?title=Q105349871&type=revision&diff=1365519277&oldid=1356145998)

##### Curation interface 

A web-based (Kotlin, Spring Boot for the back-end, and TypeScript with Vue for the front-end) curation interface is currently in construction.
It will allow mass-editing of entries and navigate quick navigation in the SSOT for the curation of new and existing entries.
This new interface is intended to become open to the public to foster the curation of entries by further means, driven by the users.
In line with the overall LOTUS approach, any modification made in this curation interface will be mirrored after validation on Wikidata and LNPN.
